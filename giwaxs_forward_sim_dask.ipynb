{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f199c5d8-9ad6-4416-87dd-6ec0d8ab4a17",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67602eed-eff9-442d-b8c4-faaaaa502936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "from scipy.signal import convolve\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from numpy.fft import fftn, fftshift\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask.diagnostics import ProgressBar\n",
    "import flox\n",
    "import flox.xarray\n",
    "from flox.xarray import xarray_reduce\n",
    "import xrft\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e15d58-e7c1-43f1-848d-0b0fcd49255f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://127.0.0.1:43027\")\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab41405-c6a7-4543-ab30-dc1a054f33a8",
   "metadata": {},
   "source": [
    "# import local files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74b8a6-e1b4-4444-a344-07c96902d42a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ptable_dict import ptable, atomic_masses\n",
    "from utilities import write_xyz, load_xyz, rotation_matrix, gaussian_kernel\n",
    "from meshgrids import generate_density_grid, convert_grid_qspace, plot_3D_grid, generate_electron_grid_npys, load_npy_files_to_dask\n",
    "from detector import make_detector, rotate_about_normal, rotate_about_horizontal, rotate_about_vertical, intersect_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd801e01-e1e4-4e08-b8ab-6e4690ead83d",
   "metadata": {},
   "source": [
    "# Generate and plot real-space voxel map for xyz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bbd3d0-bcf2-4905-a9b9-98160f05ab60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define base path\n",
    "basePath = pathlib.Path('/nsls2/users/alevin/repos/giwaxs_forward_sim')\n",
    "xyzPath = basePath.joinpath('test_xyz_files/graphite_small.xyz')\n",
    "npySavePath = pathlib.Path('/nsls2/users/alevin/misc_data/density_grid_segments/graphite_medium')\n",
    "\n",
    "sigma = 0.2\n",
    "voxel_size = 0.05\n",
    "min_ax_size = 1024\n",
    "segments = 8  # segments along x\n",
    "\n",
    "x_axis, y_axis, z_axis, grid_vox_x, grid_vox_y, grid_vox_z = generate_electron_grid_npys(xyzPath, \n",
    "                                                                                         voxel_size, \n",
    "                                                                                         segments,\n",
    "                                                                                         npySavePath,\n",
    "                                                                                         sigma,\n",
    "                                                                                         min_ax_size=min_ax_size)\n",
    "\n",
    "# Below loads the numpy array stacks into a dask array\n",
    "# I've so far been unable to fit this all into the separate python script without \n",
    "# running into strange moduleimport errors... but this should work!\n",
    "def load_array_from_npy_stack(npy_paths):\n",
    "    \"\"\"\"\"\"\n",
    "    arrs = []\n",
    "    for npy_path in npy_paths:\n",
    "        arr = np.load(npy_path)\n",
    "        arrs.append(arr)\n",
    "\n",
    "    return np.concatenate(arrs, axis=1)   \n",
    "\n",
    "npy_paths = sorted(npySavePath.glob('*.npy'))\n",
    "density_grid = dask.delayed(load_array_from_npy_stack)(npy_paths)\n",
    "density_grid = dask.array.from_delayed(density_grid, shape=(grid_vox_y, grid_vox_x, grid_vox_z), dtype=float)\n",
    "density_grid = density_grid.rechunk((grid_vox_y, int(grid_vox_x/8), grid_vox_z))\n",
    "\n",
    "density_grid = density_grid.persist()\n",
    "density_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7254397e-4e42-465a-8cb8-6460b8817b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Populate grid segments:\n",
    "# # Sort coordinates & symbols by the x coordinate value (by entering as the last column in np.lexsort)\n",
    "# ind = np.lexsort((coords[:,2], coords[:,1], coords[:,0]))  # return sorted indices values (first value)\n",
    "# # ind = np.lexsort((coords[:,2], coords[:,0], coords[:,1]))  # return sorted indices values (first value)\n",
    "# # ind = np.lexsort((coords[:,0], coords[:,1], coords[:,2]))  # return sorted indices values (first value)\n",
    "# symbols = symbols[ind]\n",
    "# coords = coords[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e238d6a-ca18-44be-9e62-0a64675222e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new array to store the shifted values\n",
    "shifted_cuts = np.zeros_like(coord_idx_cuts, dtype=float)\n",
    "\n",
    "# Compute the shifted values\n",
    "shifted_cuts[0] = coord_idx_cuts[0] / 2  # First element is the average of itself and zero\n",
    "for i in range(1, len(coord_idx_cuts)):\n",
    "    shifted_cuts[i] = (coord_idx_cuts[i] + coord_idx_cuts[i - 1]) / 2\n",
    "    \n",
    "shifted_cuts = shifted_cuts.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f967a-d29d-470d-b89c-9c47c98be2ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "taken_coords = coords[:,axis][coord_idx_cuts]\n",
    "# Create a new array to store the shifted values\n",
    "empty_coords = np.zeros_like(taken_coords, dtype=float)\n",
    "# Compute the shifted values\n",
    "empty_coords[0] = taken_coords[0] / 2  # First element is the average of itself and zero\n",
    "for i in range(1, len(taken_coords)):\n",
    "    empty_coords[i] = (taken_coords[i] + taken_coords[i - 1]) / 2\n",
    "empty_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c356b-794e-49e9-9066-40b8f98db572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coords[:,axis][shifted_cuts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8723271-4061-4425-9155-0c8510ba03e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff_threshold = voxel_size + (3 * sigma)  # set diff threshold by voxel size + (3*sigma) \n",
    "diff_axis = np.diff(coords, axis=axis)[:, 0]  # get difference values array\n",
    "diff_axis = np.append(diff_axis, 0)  # add extra zero at the end to make same shape as coords to use as mask\n",
    "coord_idx_cuts = np.nonzero(diff_axis>diff_threshold)[0] + 1 # find indices with difference value from previous greater than diff threshold \n",
    "\n",
    "# grid_vox_axis = (coords[:,axis][coord_idx_cuts] / voxel_size).astype(int)  # convert to number of voxels, these are allowed positions to segment\n",
    "grid_vox_axis = (coords[:,axis][shifted_cuts] / voxel_size).astype(int)  # convert to number of voxels, these are allowed positions to segment\n",
    "\n",
    "print('num idx vox')\n",
    "for num, coord_idx, empty_idx, vox in zip(np.arange(len(coord_idx_cuts)), coord_idx_cuts, shifted_cuts, grid_vox_axis):\n",
    "    print(num, coord_idx, empty_idx, vox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44978389-c3fe-438d-a0f5-7457383e2150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vox_break_targs = np.arange(grid_vox_segment, min_ax_size, grid_vox_segment)\n",
    "\n",
    "vox_breaks = np.array([0, min_ax_size])\n",
    "for vox_break_targ in vox_break_targs:\n",
    "    if vox_break_targ > grid_vox_axis[-1]:\n",
    "        vox_breaks = np.append(vox_breaks, vox_break_targ)\n",
    "    else:\n",
    "        vox_break_diffs = np.abs(grid_vox_axis - vox_break_targ)\n",
    "        vox_break_shifted = grid_vox_axis[vox_break_diffs==vox_break_diffs.min()][0]\n",
    "        vox_breaks = np.append(vox_breaks, vox_break_shifted)\n",
    "        \n",
    "vox_breaks.sort()\n",
    "\n",
    "vox_axis_mins = vox_breaks[:-1]\n",
    "vox_axis_maxs = vox_breaks[1:]\n",
    "vox_axis_slices = [(vox_axis_min,vox_axis_max) for vox_axis_min,vox_axis_max in zip(vox_axis_mins,vox_axis_maxs)]\n",
    "vox_axis_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d4eb0-81a7-4d8a-bf8e-867aeb527861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find all voxels along axis where there is enough space between point smeared with gaussian\n",
    "diff_threshold = voxel_size + (5 * sigma)  # set diff threshold by voxel size + (3*sigma) \n",
    "diff_axis = np.diff(coords, axis=axis)[:, 0]  # get difference values array\n",
    "diff_axis = np.append(diff_axis, 0)  # add extra zero at the end to make same shape as coords to use as mask\n",
    "coord_idx_cuts = np.nonzero(diff_axis>diff_threshold)[0] + 1  # find indices with difference value from previous greater than diff threshold \n",
    "grid_vox_axis = (coords[:,axis][coord_idx_cuts] / voxel_size).astype(int)  # convert to number of voxels, these are allowed positions to segment\n",
    "\n",
    "\n",
    "diff_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a84ac1-ed35-41f3-8f75-aafd07b01797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Cell for testing with segments being inputted as carefully selected list of grid_vox_x segments\n",
    "\n",
    "# Define base path\n",
    "basePath = pathlib.Path('/nsls2/users/alevin/repos/giwaxs_forward_sim')\n",
    "xyz_path = basePath.joinpath('test_xyz_files/graphite_medium.xyz')\n",
    "npySavePath = pathlib.Path('/nsls2/users/alevin/misc_data/density_grid_segments/',\n",
    "                           'graphite_medium_testing')\n",
    "npySavePath.mkdir(exist_ok=True)\n",
    "\n",
    "sigma = 0.1\n",
    "voxel_size = 0.045\n",
    "min_ax_size = 512\n",
    "axis_to_chunk = 'x'\n",
    "segments_type = 'flexible'  # for spacing between splits in the data, vs 'fixed' for fixed integer value\n",
    "# segments = 8  # if segments type if 'fixed', number of segments along axis to chunk\n",
    "grid_vox_segment = 128  # if segments type is 'flexible', target number for grid_vox_x\n",
    "\n",
    "# Extracting the atomic symbols and positions from the xyz file\n",
    "coords, symbols = load_xyz(xyz_path)\n",
    "\n",
    "# Shift coords array to origin (buffer ensures room for Gaussian smearing)\n",
    "buffer = 3 * sigma # same size as guassian kernel (made later)\n",
    "coords[:,0] -= np.min(coords[:,0])-buffer\n",
    "coords[:,1] -= np.min(coords[:,1])-buffer\n",
    "coords[:,2] -= np.min(coords[:,2])-buffer\n",
    "\n",
    "# Axis grids\n",
    "grid_size_x = int(np.ceil((np.max(coords[:,0])+buffer)/voxel_size))\n",
    "grid_size_y = int(np.ceil((np.max(coords[:,1])+buffer)/voxel_size))\n",
    "grid_size_z = int(np.ceil((np.max(coords[:,2])+buffer)/voxel_size))\n",
    "\n",
    "# Calcuate number of voxel grid points, pad to nearest 2^n\n",
    "grid_vox_x = 1 << (grid_size_x - 1).bit_length()\n",
    "grid_vox_y = 1 << (grid_size_y - 1).bit_length()\n",
    "grid_vox_z = 1 << (grid_size_z - 1).bit_length()\n",
    "if grid_vox_x < min_ax_size:\n",
    "    grid_vox_x = min_ax_size\n",
    "if grid_vox_y < min_ax_size:\n",
    "    grid_vox_y = min_ax_size\n",
    "if grid_vox_z < min_ax_size:\n",
    "    grid_vox_z = min_ax_size\n",
    "\n",
    "# Create axes\n",
    "x_axis = np.linspace(0, grid_vox_x*voxel_size, grid_vox_x)\n",
    "y_axis = np.linspace(0, grid_vox_y*voxel_size, grid_vox_y)\n",
    "z_axis = np.linspace(0, grid_vox_z*voxel_size, grid_vox_z)\n",
    "\n",
    "# Sort coordinates & symbols by the specifed axis coordinate value (by entering as the last column in np.lexsort)\n",
    "# Extract int for axis to chunk\n",
    "if axis_to_chunk == 'x':\n",
    "    axis = 0\n",
    "    ind = np.lexsort((coords[:,2], coords[:,1], coords[:,0]))\n",
    "elif axis_to_chunk == 'y':\n",
    "    axis = 1\n",
    "    ind = np.lexsort((coords[:,2], coords[:,0], coords[:,1]))\n",
    "elif axis_to_chunk == 'z':\n",
    "    axis = 2\n",
    "    ind = np.lexsort((coords[:,0], coords[:,1], coords[:,2]))\n",
    "symbols = symbols[ind]\n",
    "coords = coords[ind]\n",
    "\n",
    "# Find all voxels along axis where there is enough space between point smeared with gaussian\n",
    "diff_threshold = voxel_size + (5 * sigma)  # set diff threshold by voxel size + (3*sigma) \n",
    "diff_axis = np.diff(coords, axis=axis)[:, 0]  # get difference values array\n",
    "diff_axis = np.append(diff_axis, 0)  # add extra zero at the end to make same shape as coords to use as mask\n",
    "coord_idx_cuts = np.nonzero(diff_axis>diff_threshold)[0] # + 1  # find indices with difference value from previous greater than diff threshold \n",
    "taken_coords = coords[:,axis][coord_idx_cuts]\n",
    "# Create a new array to store the shifted values\n",
    "empty_coords = np.zeros_like(taken_coords, dtype=float)\n",
    "# Compute the shifted values\n",
    "empty_coords[0] = taken_coords[0] / 2  # First element is the average of itself and zero\n",
    "for i in range(1, len(taken_coords)):\n",
    "    empty_coords[i] = (taken_coords[i] + taken_coords[i - 1]) / 2\n",
    "grid_vox_axis = (empty_coords / voxel_size).astype(int)  # convert to number of voxels, these are allowed positions to segment\n",
    "\n",
    "# Based on allowed voxel points above, define voxel slices along specified axis\n",
    "vox_break_targs = np.arange(grid_vox_segment, min_ax_size, grid_vox_segment)  # target voxel breakpoints (not including 0 & end)\n",
    "\n",
    "# Generate actual allowed break points\n",
    "vox_breaks = np.array([0, min_ax_size])\n",
    "for vox_break_targ in vox_break_targs:\n",
    "    if vox_break_targ > grid_vox_axis[-1]:\n",
    "        vox_breaks = np.append(vox_breaks, vox_break_targ)\n",
    "    else:\n",
    "        vox_break_diffs = np.abs(grid_vox_axis - vox_break_targ)\n",
    "        vox_break_shifted = grid_vox_axis[vox_break_diffs==vox_break_diffs.min()][0]\n",
    "        vox_breaks = np.append(vox_breaks, vox_break_shifted)\n",
    "vox_breaks.sort()\n",
    "\n",
    "# Reshape breakpoints into tuples of min/max\n",
    "vox_axis_mins = vox_breaks[:-1]\n",
    "vox_axis_maxs = vox_breaks[1:]\n",
    "vox_axis_slices = [(vox_axis_min,vox_axis_max) for vox_axis_min,vox_axis_max in zip(vox_axis_mins,vox_axis_maxs)]\n",
    "x_mins = x_axis[vox_axis_mins]\n",
    "x_maxs = x_axis[vox_axis_maxs[:-1]]\n",
    "x_maxs = np.append(x_maxs, x_axis[-1])\n",
    "\n",
    "# Loop over each vox segment to populate\n",
    "grid_vox_segments = np.array([])\n",
    "for i, vox_axis_slice in enumerate(tqdm(vox_axis_slices, desc='Populating & saving grid segments')):\n",
    "    # Get segment size\n",
    "    grid_vox_axis_segment = vox_axis_slices[i][1] - vox_axis_slices[i][0]\n",
    "    grid_vox_segments = np.append(grid_vox_segments, grid_vox_axis_segment)\n",
    "    \n",
    "    if axis_to_chunk=='x':\n",
    "        # Create empty grid segment\n",
    "        density_grid_segment = np.zeros((grid_vox_y, grid_vox_axis_segment, grid_vox_z))\n",
    "        \n",
    "        # Slice x_axis for segment to identify x maximum and minimum\n",
    "        # x_axis_slice = x_axis[ i * grid_vox_axis_segment:\n",
    "        #                       (i+1) * grid_vox_axis_segment ]\n",
    "        x_min = x_mins[i]\n",
    "        x_max = x_maxs[i]\n",
    "\n",
    "        # Downselect pre-sorted coords & symbols segment to apply to loop\n",
    "        segment_coords_mask = (coords[:,axis] >= x_min) & (coords[:,axis] < x_max)\n",
    "        segment_coords = coords[segment_coords_mask]\n",
    "        segment_symbols = symbols[segment_coords_mask]\n",
    "\n",
    "        # Populate the grid \n",
    "        print(int(grid_vox_segments.sum()))\n",
    "        for coord, symbol in zip(segment_coords, segment_symbols):\n",
    "            grid_coord = np.round((coord / voxel_size),0).astype('int')\n",
    "            density_grid_segment[ grid_coord[1], \n",
    "                                 (grid_coord[0]-(int(grid_vox_segments.sum()))),  # here I think is the error! \n",
    "                                  grid_coord[2] ] += (ptable[symbol])  \n",
    "            \n",
    "        # Create a Gaussian kernel\n",
    "        if sigma:\n",
    "            sigma_voxel = sigma/voxel_size\n",
    "            kernel_size = 6 * sigma_voxel + 1  # Ensure the kernel size covers enough of the Gaussian\n",
    "            gaussian_kernel_3d = gaussian_kernel(kernel_size, sigma_voxel)\n",
    "            # convolve gaussian with \n",
    "            density_grid_segment = convolve(density_grid_segment, gaussian_kernel_3d, mode='same')\n",
    "            print('did_convolution')\n",
    "            \n",
    "        npy_savename = f'grid_segment_along-x_num-{i}_shape-{grid_vox_y}-{grid_vox_axis_segment}-{grid_vox_z}.npy'\n",
    "        np.save(npySavePath.joinpath(npy_savename), density_grid_segment)\n",
    "            \n",
    "    elif axis_to_chunk=='y':\n",
    "        # density_grid_segment = np.zeros((grid_vox_axis_segment, grid_vox_x, grid_vox_z))\n",
    "        print('not implemented yet')\n",
    "    elif axis_to_chunk=='z':\n",
    "        # density_grid_segment = np.zeros((grid_vox_y, grid_vox_x, grid_vox_axis_segment))\n",
    "        print('not implemented yet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75238190-3b85-4560-b25f-75ebfda371d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vox_axis_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d6faa-adfb-444a-8c9d-b0e796b60d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Below loads the numpy array stacks into a dask array\n",
    "# I've so far been unable to fit this all into the separate python script without \n",
    "# running into strange moduleimport errors... but this should work!\n",
    "def load_array_from_npy_stack(npy_paths):\n",
    "    \"\"\"\"\"\"\n",
    "    arrs = []\n",
    "    for npy_path in npy_paths:\n",
    "        arr = np.load(npy_path)\n",
    "        arrs.append(arr)\n",
    "\n",
    "    return np.concatenate(arrs, axis=1)   \n",
    "\n",
    "npy_paths = sorted(npySavePath.glob('*.npy'))\n",
    "density_grid = dask.delayed(load_array_from_npy_stack)(npy_paths)\n",
    "density_grid = dask.array.from_delayed(density_grid, shape=(grid_vox_y, grid_vox_x, grid_vox_z), dtype=float)\n",
    "# density_grid = density_grid.rechunk((grid_vox_y, int(grid_vox_x/8), grid_vox_z))\n",
    "density_grid = density_grid.rechunk({0:-1, 1:int(grid_vox_x/8), 2:-1})\n",
    "\n",
    "density_grid = density_grid.persist()\n",
    "density_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c015444d-aeca-4979-b10b-d18da4c63979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# put loaded numpy array into xarray dataarray\n",
    "dens_grid_DA = xr.DataArray(data=density_grid,\n",
    "                            dims=['y', 'x', 'z'],\n",
    "                            coords={'y':y_axis,\n",
    "                                    'x':x_axis,\n",
    "                                    'z':z_axis})\n",
    "\n",
    "# # Dask-ify it\n",
    "# num_chunks = 8\n",
    "# dens_grid_DA = dens_grid_DA.chunk({'x':int(len(dens_grid_DA.x)/num_chunks)})  # chunk along just one dimension, for slab fftw(?)\n",
    "dens_grid_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cfc3d-3cf7-4706-8b4a-52781eecce0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "density_grid.sum(axis=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e980617-9cac-4b5c-9749-48590741c303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summed_z_arr = density_grid.sum(axis=2).compute()\n",
    "summed_z_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b1799-e70a-4426-a125-e91d32ed1389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "# smeared_z_arr = gaussian_filter(summed_z_arr, sigma=5)\n",
    "plt.imshow(density_grid.sum(axis=2).compute(), origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f1d8d3-18a4-4483-b8b8-0eb10a0d1147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# dens_grid_DA.reduce(np.nanpercentile, q=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97264771-1c36-45e2-9716-d94fbdd66eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# lazy_clims = da.percentile(dens_grid_DA.data.ravel(), [0.1, 0.99])\n",
    "# lazy_clims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c51935-5a8d-44ae-bf5e-bddfee865714",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lazy_binned_DA = dens_grid_DA.groupby_bins('x', 128).mean().groupby_bins('y',128).mean().groupby_bins('z',128).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd9886-ff17-4073-80a1-32c6777ccd75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lazy_binned_DA.data.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2384f19a-1e9b-4147-8f76-50f90a5d84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "binned_DA = lazy_binned_DA.persist()\n",
    "\n",
    "display(binned_DA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5359039b-2af0-4162-aa21-0dbbe463c7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_DA = binned_DA.assign_coords({\n",
    "            'x': ('x_bins', np.array([interval.mid for interval in binned_DA.x_bins.data])),\n",
    "            'y': ('y_bins', np.array([interval.mid for interval in binned_DA.y_bins.data])),\n",
    "            'z': ('z_bins', np.array([interval.mid for interval in binned_DA.z_bins.data]))\n",
    "                   }).swap_dims({'x_bins':'x', 'y_bins':'y', 'z_bins':'z'})\n",
    "binned_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ffcb00-7742-488b-9343-6f01148c4f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "threshold = 99.9\n",
    "num_levels = 10\n",
    "cmap = 'plasma'\n",
    "fig, ax = plot_3D_grid(density_grid.compute(), x_axis, y_axis, z_axis, cmap, threshold, num_levels, log=True)\n",
    "# fig, ax = plot_3D_grid(binned_DA.data.compute(), binned_DA.x.data, binned_DA.y.data, binned_DA.z.data, cmap, threshold, num_levels, log=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373acd00-ab72-4311-b130-a80cbd81cdd6",
   "metadata": {},
   "source": [
    "# Generate and plot reciprocal space voxel map for xyz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb91f5-f3d7-4b51-a820-1b47c3ba3400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xrft_iq(DA, num_chunks):\n",
    "    fft_yz = xrft.fft(DA, dim=['y','z'])  # take dft in y & z direction\n",
    "    fft_yz_rechunked = fft_yz.chunk({'freq_y':int(len(DA.y))/num_chunks,'x':int(len(DA.x))})  # rechunk along y direction \n",
    "    fft_all = xrft.fft(fft_yz_rechunked, dim=['x'])  # take dft in x direction\n",
    "    iq_DA = np.abs(fft_all)**2\n",
    "    \n",
    "    return iq_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c2ed0a-4a54-4fe3-acf3-0509262659ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "num_chunks = 8\n",
    "iq_DA = xrft_iq(dens_grid_DA, num_chunks)  #.compute()\n",
    "iq_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469356c8-61c4-4f15-ba98-da7782fe1520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iq_DA.data.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed464bd-349a-48a9-96bf-f1d30c4464f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "iq_DA = iq_DA.persist()\n",
    "iq_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d768e92-182b-4b6b-9faf-653e012f1d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fft_yz = xrft.fft(dens_grid_DA, dim=['y','z'])  # take dft in y & z direction\n",
    "fft_yz_rechunked = fft_yz.chunk({'freq_y':int(len(dens_grid_DA.y))/8,'x':int(len(dens_grid_DA.x))})  # rechunk along y direction \n",
    "fft_all = xrft.fft(fft_yz_rechunked, dim=['x'])  # take dft in x direction\n",
    "# with ProgressBar():\n",
    "\n",
    "# fft_all = fft_all.persist()\n",
    "\n",
    "fft_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1add8c4-a969-4828-a9a5-5cb68f521394",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_yz.data.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e254a064-d75e-40a0-bf09-63ca29ccc899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fft_all.data.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaad596-e5e0-44da-a0f8-5448f4e0848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_all = fft_all.compute()\n",
    "fft_all.data.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b788f-1ff3-47ea-8977-f5c53702d662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iq_DA = np.abs(fft_all)**2\n",
    "persisted_iq_DA = iq_DA.persist()\n",
    "persisted_iq_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26232e90-00cd-4b2a-a05a-0425ed802031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fft_DA = xrft.fft(dens_grid_DA, chunks_to_segments=True).mean(['x_segment', 'y_segment', 'z_segment'])\n",
    "# fft_DA = fft_DA.rename({'freq_y':'qy', 'freq_x':'qx', 'freq_z':'qz'})\n",
    "# iq_DA = np.abs(fft_DA)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f3d859-4bf2-4630-a4d8-ff4382cc5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "with ProgressBar():\n",
    "    iq_DA = iq_DA.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a185c5d-920f-4f04-b380-1d236d463b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iq, qx, qy, qz = convert_grid_qspace(dens_grid, x_axis, y_axis, z_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8dd9e5-64ca-4494-9a79-e8c1811aaad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "threshold = 99.9\n",
    "num_levels = 10\n",
    "cmap = 'plasma'\n",
    "fig, ax = plot_3D_grid(iq, qx, qy, qz, cmap, threshold, num_levels)\n",
    "# fig, ax = plot_3D_grid(iq, qx, qy, qz, cmap, threshold, num_levels)\n",
    "\n",
    "# ax.set_xlim((-3,3))\n",
    "# ax.set_ylim((-3,3))\n",
    "# ax.set_zlim((-3,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e877a6e4-09fc-4e77-924d-334ae0ceea4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del iq_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4dff1f-7d5a-4123-920f-e3788699d0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iq_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a45526a-fa45-48dc-98ba-25e9cf8451d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "persited_iq_DA = iq_DA.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40cb28a-c261-4330-91fc-cea97ec12ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "threshold = 99.9\n",
    "num_levels = 10\n",
    "cmap = 'plasma'\n",
    "fig, ax = plot_3D_grid(iq_DA.data.compute(), iq_DA.freq_x.data*2*np.pi, iq_DA.freq_y.data*2*np.pi, iq_DA.freq_z.data*2*np.pi, cmap, threshold, num_levels)\n",
    "# fig, ax = plot_3D_grid(iq_DA.data, iq_DA.freq_x.data*2*np.pi, iq_DA.freq_y.data*2*np.pi, iq_DA.freq_z.data*2*np.pi, cmap, threshold, num_levels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e91453f-ad59-415d-9892-9e6e4db825d1",
   "metadata": {},
   "source": [
    "# find q-resolutions\n",
    "### The frequency resolution (qbin size) is given by sampling rate (1/voxel_size) over box size (size of molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74345a01-04d9-4c7e-9939-a8f23c4049dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = qx\n",
    "y_vals = qy\n",
    "z_vals = qz\n",
    "qx_res = x_vals[1]-x_vals[0]\n",
    "qy_res = y_vals[1]-y_vals[0]\n",
    "qz_res = z_vals[1]-z_vals[0]\n",
    "print(f'Resolutions are [qx={qx_res:.4f}, qy={qy_res:.4f}, qz={qz_res:.4f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ee5b4-0cb4-4f2d-b171-a4aa8452b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = iq_DA.qx.data*2*np.pi\n",
    "y_vals = iq_DA.qy.data*2*np.pi\n",
    "z_vals = iq_DA.qz.data*2*np.pi\n",
    "qx_res = x_vals[1]-x_vals[0]\n",
    "qy_res = y_vals[1]-y_vals[0]\n",
    "qz_res = z_vals[1]-z_vals[0]\n",
    "print(f'Resolutions are [qx={qx_res:.4f}, qy={qy_res:.4f}, qz={qz_res:.4f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c52ab30-a74d-44c3-8201-64786de5fdc5",
   "metadata": {},
   "source": [
    "# Set up Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa3e2c-e025-4ed4-9cbe-b670e72fa5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_pixels = (200,200) #horizontal, vertical\n",
    "det_qs = (8,8) #horizontal, vertical (these are absolute maximums. detector centered at 0)\n",
    "det_x_grid, det_y_grid, det_z_grid, det_h, det_v = make_detector(det_qs[0], det_pixels[0], det_qs[1], det_pixels[1])\n",
    "\n",
    "psi = 0 #rotation in degrees of detector about detector normal axis\n",
    "det_x_grid, det_y_grid, det_z_grid = rotate_about_normal(det_x_grid, det_y_grid, det_z_grid, psi)\n",
    "phi = 0 #rotation in degrees of detector about detector vertical axis\n",
    "det_x_grid, det_y_grid, det_z_grid = rotate_about_vertical(det_x_grid, det_y_grid, det_z_grid, phi)\n",
    "theta = 0 #rotation in degrees of detector about detector horizontal axis\n",
    "det_x_grid, det_y_grid, det_z_grid = rotate_about_horizontal(det_x_grid, det_y_grid, det_z_grid, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7794554d-f1bb-4787-8fb3-f6151861426c",
   "metadata": {},
   "source": [
    "# plot single detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf26c9-fcbb-486a-9b7c-cc40fb707da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_ints = intersect_detector(iq, qx, qy, qz, det_x_grid, det_y_grid, det_z_grid, det_h, det_v)\n",
    "\n",
    "# plot\n",
    "fig, ax1 = subplots()\n",
    "ax1.imshow(det_ints,\n",
    "           norm=matplotlib.colors.Normalize(vmin=np.percentile(det_ints, 10), vmax=np.percentile(det_ints, 99)),\n",
    "           extent=(np.min(det_h),np.max(det_h),np.min(det_v),np.max(det_v)),\n",
    "           cmap='turbo',\n",
    "           origin = 'lower')\n",
    "ax1.set_xlabel('q horizontal')\n",
    "ax1.set_ylabel('q vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770a49ac-086d-4145-ba07-40d4b93fad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_ints = intersect_detector(iq_DA.data, iq_DA.qx.data*2*np.pi, iq_DA.qy.data*2*np.pi, iq_DA.qz.data*2*np.pi, det_x_grid, det_y_grid, det_z_grid, det_h, det_v)\n",
    "\n",
    "# plot\n",
    "fig, ax1 = subplots()\n",
    "ax1.imshow(det_ints,\n",
    "           norm=matplotlib.colors.Normalize(vmin=np.percentile(det_ints, 10), vmax=np.percentile(det_ints, 99)),\n",
    "           extent=(np.min(det_h),np.max(det_h),np.min(det_v),np.max(det_v)),\n",
    "           cmap='turbo',\n",
    "           origin = 'lower')\n",
    "ax1.set_xlabel('q horizontal')\n",
    "ax1.set_ylabel('q vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c099c7-8aa3-44f8-a73b-fa83514d333d",
   "metadata": {},
   "source": [
    "# Generate and sum multiple plots across selected angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ed969-a998-4c24-9213-db8653ed9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_detector_ints(det_pixels, det_qs, psi, phi, theta):\n",
    "    det_x_grid, det_y_grid, det_z_grid, det_h, det_v = make_detector(det_qs[0], det_pixels[0], det_qs[1], det_pixels[1])\n",
    "    \n",
    "    # psi = 0 #rotation in degrees of detector about detector normal axis\n",
    "    det_x_grid, det_y_grid, det_z_grid = rotate_about_normal(det_x_grid, det_y_grid, det_z_grid, psi)\n",
    "    # phi = 0 #rotation in degrees of detector about detector vertical axis\n",
    "    det_x_grid, det_y_grid, det_z_grid = rotate_about_vertical(det_x_grid, det_y_grid, det_z_grid, phi)\n",
    "    # theta = 0 #rotation in degrees of detector about detector horizontal axis\n",
    "    det_x_grid, det_y_grid, det_z_grid = rotate_about_horizontal(det_x_grid, det_y_grid, det_z_grid, theta)\n",
    "    det_ints = intersect_detector(iq, qx, qy, qz, det_x_grid, det_y_grid, det_z_grid, det_h, det_v)\n",
    "\n",
    "    return det_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74414534-90d0-4a0b-84b9-c529bfcb617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup detector\n",
    "det_pixels = (150,150) #horizontal, vertical\n",
    "det_qs = (6.5,6.5) #horizontal, vertical (these are absolute maximums. detector centered at 0)\n",
    "psi = 0 #rotation in degrees of detector about detector normal axis\n",
    "phis = np.linspace(0,180,num=60) #rotation in degrees of detector about detector vertical axis\n",
    "theta = 0 #rotation in degrees of detector about detector horizontal axis\n",
    "\n",
    "det_ints = []\n",
    "det_x_grid, det_y_grid, det_z_grid, det_h, det_v = make_detector(det_qs[0], det_pixels[0], det_qs[1], det_pixels[1])\n",
    "for i, phi in enumerate(phis):\n",
    "    det_int = generate_detector_ints(det_pixels, det_qs, psi, phi, theta)\n",
    "    if i == 0:\n",
    "        det_sum = det_int\n",
    "    else:\n",
    "        det_sum +=det_int\n",
    "    det_ints.append(det_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e590c-4aed-4b80-945c-99ab4e8a0bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "fig, ax1 = subplots()\n",
    "cax = ax1.imshow(det_sum,\n",
    "           norm=matplotlib.colors.LogNorm(vmin=np.percentile(det_sum, 30), vmax=np.percentile(det_sum, 99)),\n",
    "           extent=(np.min(det_h),np.max(det_h),np.min(det_v),np.max(det_v)),\n",
    "           cmap='turbo',\n",
    "           origin = 'lower')\n",
    "ax1.set_xlabel('q horizontal')\n",
    "ax1.set_ylabel('q vertical')\n",
    "ax1.set_xlim(left=0)\n",
    "ax1.set_ylim(bottom=0)\n",
    "cbar = fig.colorbar(cax, ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca6240c-6661-45dd-a7db-b732ed703b39",
   "metadata": {},
   "source": [
    "# Visualize each individual detector across angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c7b82c-d9cf-4875-a496-bfafa226741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97be38-02bd-4822-85f7-269bc9a18f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(det_ints[:,0,0])):\n",
    "    det_int = det_ints[i,:,:]\n",
    "    fig, ax1 = subplots()\n",
    "    cax = ax1.imshow(det_int,\n",
    "           norm=matplotlib.colors.LogNorm(vmin=np.percentile(det_int, 10), vmax=np.percentile(det_int, 99)),\n",
    "           extent=(np.min(det_h),np.max(det_h),np.min(det_v),np.max(det_v)),\n",
    "           cmap='turbo',\n",
    "           origin = 'lower')\n",
    "    ax1.set_xlabel('q horizontal')\n",
    "    ax1.set_ylabel('q vertical')\n",
    "    ax1.set_xlim(0, 3)\n",
    "    ax1.set_ylim(0, 3)\n",
    "    cbar = fig.colorbar(cax, ax=ax1)\n",
    "    ax1.set_title(f'Phi = {i*3} degrees')\n",
    "    plt.show()\n",
    "    plt.close('all')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dask",
   "language": "python",
   "name": "dask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
